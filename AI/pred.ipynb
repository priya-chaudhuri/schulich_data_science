{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive Analytics: process that aims to predict an event, using historical data \n",
    "#This data is gathered in the analytical basetable. \n",
    "#An analytical basetable is typically stored in a `pandas` dataframe. \n",
    "#There are three important concepts in the analytical basetable: \n",
    "#the population, the candidate predictors and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   target                 25000 non-null  int64  \n",
      " 1   gender_F               25000 non-null  int64  \n",
      " 2   income_high            25000 non-null  int64  \n",
      " 3   income_low             25000 non-null  int64  \n",
      " 4   country_USA            25000 non-null  int64  \n",
      " 5   country_India          25000 non-null  int64  \n",
      " 6   country_UK             25000 non-null  int64  \n",
      " 7   age                    25000 non-null  int64  \n",
      " 8   time_since_last_gift   25000 non-null  int64  \n",
      " 9   time_since_first_gift  25000 non-null  int64  \n",
      " 10  max_gift               25000 non-null  float64\n",
      " 11  min_gift               25000 non-null  float64\n",
      " 12  mean_gift              25000 non-null  float64\n",
      " 13  number_gift            25000 non-null  int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/priyachaudhuri/Desktop/SSB TERM 1/Artificial intelligence/basetable_ex2_4.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "population_size = len(df)\n",
    "print(population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187\n",
      "0.04748\n"
     ]
    }
   ],
   "source": [
    "targets = sum(df['target'])\n",
    "print(targets)\n",
    "# Print the target incidence.\n",
    "print(targets / population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12579\n",
      "12421\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of females.\n",
    "print(sum(df['gender_F'] == 1))\n",
    "\n",
    "# Count and print the number of males.\n",
    "print(sum(df['gender_F'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00784128]]\n",
      "[-3.42758047]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyachaudhuri/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Univariate Logistic Regression\n",
    "# ax+b\n",
    "logreg = linear_model.LogisticRegression()\n",
    "X = df[['age']]\n",
    "y = df[['target']]\n",
    "logreg.fit(X,y)\n",
    "\n",
    "#observe the coefficient that corresponds with the predictor age\n",
    "print(logreg.coef_)\n",
    "\n",
    "#retrieve the intercept \n",
    "print(logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyachaudhuri/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00761093  0.03892997 -0.21164388]]\n",
      "[-7.96434659]\n"
     ]
    }
   ],
   "source": [
    "# Multivariate Logistic Regression\n",
    "# a1x1+a2x2+a3x3....anxn+b\n",
    "X = df[['age', 'max_gift', 'income_low']]\n",
    "y = df[['target']]\n",
    "logreg.fit(X,y)\n",
    "print(logreg.coef_)\n",
    "print(logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you built a logistic regression model to predict which donors are most likely to donate for a project\n",
    "# using age and time_since_last_gift (number of months since the last gift) as predictors. \n",
    "# The output of the logistic regression model is as follows:\n",
    "# y = 0.3 + 4.5*age - 2.3*time_since_last_gift\n",
    "# Which of the following statements holds, according to the model?\n",
    "#### Older donors that recently donated are most likely to donate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyachaudhuri/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\t0.007801469599054385\n",
      "gender_F\t0.1096434126464954\n",
      "time_since_last_gift\t-0.0012872607039949647\n",
      "[-2.59072469]\n"
     ]
    }
   ],
   "source": [
    "# Import linear_model from sklearn.\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create a DataFrame X that only contains the candidate predictors age, gender_F and time_since_last_gift.\n",
    "X = df[['age', 'gender_F', 'time_since_last_gift']]\n",
    "\n",
    "# Create a DataFrame y that contains the target.\n",
    "y = df[['target']]\n",
    "\n",
    "# Construct a logistic regression model that predicts the target using age, gender_F and time_since_last gift\n",
    "# Create a logistic regression model logreg and fit it to the data.\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Assign the coefficients to a list coef\n",
    "coef = logreg.coef_\n",
    "for p,c in zip(X,list(coef[0])):\n",
    "    print(p + '\\t' + str(c))\n",
    "    \n",
    "# Assign the intercept to the variable intercept\n",
    "intercept = logreg.intercept_\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyachaudhuri/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93439418 0.06560582]\n",
      " [0.94519285 0.05480715]\n",
      " [0.92097941 0.07902059]\n",
      " [0.95296422 0.04703578]\n",
      " [0.94672824 0.05327176]]\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression model\n",
    "X = df[[\"age\",\"gender_F\",\"time_since_last_gift\"]] # # Candidate Predictors\n",
    "\n",
    "y = df[[\"target\"]]\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Create a DataFrame new_data from current_data that has only the relevant predictors \n",
    "new_data = df[[\"age\",\"gender_F\",\"time_since_last_gift\"]]\n",
    "\n",
    "# Make a prediction for each observation in new_data and assign it to predictions\n",
    "predictions = logreg.predict_proba(new_data)\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models with many variables are not necessarily better models\n",
    "# This is due to a phenomenon called over-fitting\n",
    "# harder to maintain or implement\n",
    "# harder to interprent, multi- collinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of variable selection is to select a set of variables that has optimal performance. \n",
    "# A measure often used to quantify the performance of predictive models is the AUC value. \n",
    "# number between 0 and 1 that expresses how well the model can order the objects from low chance to be a target to high chance to be a target\n",
    "# Perfect models - AUC = 1\n",
    "# Random models -  AUC =  0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = logreg.predict_proba(X)\n",
    "predictions_target = predictions[:,1]\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc = roc_auc_score(y, predictions_target)\n",
    "print(round(auc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create appropriate DataFrames\n",
    "X_1 = df[variables_1]\n",
    "X_2 = df[variables_2]\n",
    "y = df[[\"target\"]]\n",
    "\n",
    "# Create the logistic regression model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# Make predictions using the first set of variables and assign the AUC to auc_1\n",
    "logreg.fit(X_1, y)\n",
    "predictions_1 = logreg.predict_proba(X_1)[:,1]\n",
    "auc_1 = roc_auc_score(y, predictions_1)\n",
    "\n",
    "# Make predictions using the second set of variables and assign the AUC to auc_2\n",
    "logreg.fit(X_2, y)\n",
    "predictions_2 = logreg.predict_proba(X_2)[:,1]\n",
    "auc_2 = roc_auc_score(y, predictions_2)\n",
    "\n",
    "# Print auc_1 and auc_2\n",
    "print(round(auc_1,2))\n",
    "print(round(auc_2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward stepwise variable selection\n",
    "# 1. it selects among all candidate predictors the variable that has the best AUC when used in a model.\n",
    "# 2. it selects another candidate predictor that has the best AUC in combination with the first selected variable. \n",
    "# 3. This scheme continues until you added all candidate predictors, or until you obtain a predefined number of variables.\n",
    "\n",
    "# Implementing the forward stepwise procedure goes smoothly if you split the task in smaller chunks. \n",
    "# 1. implement a function that returns the AUC of a model built with a given variable set\n",
    "# 2. code a function that returns the next best variable to add. \n",
    "# 3. use these functions to add variables in a stepwise manner until you reach the desired variable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyachaudhuri/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "def auc_cal(variables, target, basetable):\n",
    "    X = df[variables]\n",
    "    y = df[target]\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    logreg.fit(X, y)\n",
    "    \n",
    "    predictions = logreg.predict_proba(X)[:,1]\n",
    "    auc = roc_auc_score(y, predictions)\n",
    "    \n",
    "    return(auc)\n",
    "\n",
    "auc = auc_cal([\"age\",\"gender_F\"],[\"target\"],df)\n",
    "print(round(auc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_gift\n"
     ]
    }
   ],
   "source": [
    "def next_best(current_variables,candidate_variables, target, df):\n",
    "    best_auc = -1\n",
    "    best_variable = None\n",
    "    for v in candidate_variables:\n",
    "        auc_v = auc_cal(current_variables + [v], target, df)\n",
    "        if auc_v >= best_auc:\n",
    "            best_auc = auc_v\n",
    "            best_variable = v\n",
    "    return best_variable\n",
    "\n",
    "current_variables = [\"age\",\"gender_F\"]\n",
    "candidate_variables = [\"min_gift\",\"max_gift\",\"mean_gift\"]\n",
    "next_variable = next_best(current_variables, candidate_variables, \"target\", df)\n",
    "print(next_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7126\n",
      "age\n",
      "0.7149\n",
      "0.7131\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\" and \"min_gift\" as predictors\n",
    "auc_current = auc_cal(['max_gift', 'mean_gift', 'min_gift'], \"target\", df)\n",
    "print(round(auc_current,4))\n",
    "\n",
    "# Calculate which variable among \"age\" and \"gender_F\" should be added to the variables \"max_gift\", \"mean_gift\" and \"min_gift\"\n",
    "next_variable = next_best(['max_gift', 'mean_gift', 'min_gift'], ['age', 'gender_F'], \"target\",df)\n",
    "print(next_variable)\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"age\" as predictors\n",
    "auc_current_age = auc_cal(['max_gift', 'mean_gift', 'min_gift', 'age'], \"target\", df)\n",
    "print(round(auc_current_age,4))\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"gender_F\" as predictors\n",
    "auc_current_gender_F = auc_cal(['max_gift', 'mean_gift', 'min_gift','gender_F'], \"target\", df)\n",
    "print(round(auc_current_gender_F,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['max_gift']\n",
      "['max_gift', 'age']\n",
      "['max_gift', 'age', 'mean_gift']\n",
      "['max_gift', 'age', 'mean_gift', 'min_gift']\n",
      "['max_gift', 'age', 'mean_gift', 'min_gift', 'income_low']\n"
     ]
    }
   ],
   "source": [
    "candidate_variables = [\"mean_gift\",\"min_gift\",\"max_gift\",\"age\",\"gender_F\",\"country_USA\",\"income_low\"]\n",
    "current_variables = []\n",
    "target = \"target\"\n",
    "max_number_variables = 5\n",
    "number_iterations = min(max_number_variables, len(candidate_variables))\n",
    "for i in range(0,number_iterations):\n",
    "    next_var = next_best(current_variables,candidate_variables,target,df)\n",
    "    current_variables = current_variables + [next_var]\n",
    "    candidate_variables.remove(next_var)\n",
    "    print(current_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "0.52\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the AUC of the model using min_gift only\n",
    "auc_min_gift = auc_cal(['min_gift'], \"target\", df)\n",
    "print(round(auc_min_gift,2))\n",
    "\n",
    "# Calculate the AUC of the model using income_high only\n",
    "auc_income_high = auc_cal(['income_high'], \"target\", df)\n",
    "print(round(auc_income_high,2))\n",
    "\n",
    "# Calculate the correlation between min_gift and mean_gift\n",
    "correlation = np.corrcoef(df[\"min_gift\"], df[\"mean_gift\"])[0,1]\n",
    "print(round(correlation,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning\n",
    "# One way to partition data is by randomly dividing the data in two parts. \n",
    "# However, when the target incidence is low, it is better to make sure that the target incidence is the same in train and test, that is, to stratify on the target. \n",
    "# In python this can be done using the train_test_split method in the sklearn model-selection module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# Load the partitioning module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create DataFrames with variables and target\n",
    "X = df.drop(columns = \"target\")\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Carry out 50-50 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Check whether train and test have same percentage targets\n",
    "print(round(sum(train[\"target\"])/len(train), 2))\n",
    "print(round(sum(test[\"target\"])/len(test), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partitioning module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create DataFrames with variables and target\n",
    "X = df.drop(columns = 'target')\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Carry out 70-30 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    " # Apply the auc_train_test function\n",
    "auc_train, auc_test = auc_train_test(['age', 'gender_F'], \"target\", train, test)\n",
    "print(round(auc_train,2))\n",
    "print(round(auc_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of train and test AUC values\n",
    "auc_values_train = []\n",
    "auc_values_test = []\n",
    "\n",
    "# Add variables one by one\n",
    "variables_evaluate = []\n",
    "\n",
    "# Iterate over the variables in variables\n",
    "for v in variables:\n",
    "\n",
    "    # Add the variable\n",
    "    variables_evaluate.append(v)\n",
    "    \n",
    "    # Calculate the train and test AUC of this set of variables\n",
    "    auc_train, auc_test = auc_train_test(variables_evaluate, [\"target\"], train, test)\n",
    "    \n",
    "    # Append the values to the lists\n",
    "    auc_values_train.append(auc_train)\n",
    "    auc_values_test.append(auc_test)\n",
    "    \n",
    "# Make plot of the AUC values\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(range(0,len(auc_values_train)))\n",
    "y_train = np.array(auc_values_train)\n",
    "y_test = np.array(auc_values_test)\n",
    "plt.xticks(x, variables, rotation = 90)\n",
    "plt.plot(x,y_train)\n",
    "plt.plot(x,y_test)\n",
    "plt.ylim((0.6, 0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lift graph\n",
    "skplt.metrics.plot_lift_curve(targets_test, predictions_test)\n",
    "plt.show()\n",
    "\n",
    "# Read the lift at 40% (round it up to the upper tenth)\n",
    "perc_selected = 0.4\n",
    "lift = 1.5\n",
    "\n",
    "# Information about the campaign\n",
    "population_size, target_incidence, campaign_cost, campaign_reward = 100000, 0.01, 1, 100\n",
    "    \n",
    "# Profit if all donors are targeted\n",
    "profit_all = profit(target_incidence, 1, population_size, campaign_cost, campaign_reward)\n",
    "print(profit_all)\n",
    "\n",
    "# Profit if top 40% of donors are targeted\n",
    "profit_40 = profit(1.5 * .01, 0.4, population_size, campaign_cost, campaign_reward)\n",
    "print(profit_40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
